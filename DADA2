#####################################################################################################
############################    ANALISIS DE DATOS SECUENCIACION MASIVA    ###########################
############################    Laboratorio de Microbiologia Marina UC    ###########################
######  v3.5.1.  ###################################### Autor: Gary Vanzin modificado por LK/2019  ##

## Pasos de Analisis:

* View sequencing quality profiles
* Based on Sequence quality trim ~ 20 nt from left and anything below Q30 on the right
* dereplicate
* Perform joint sample inference and error rate estimation
* merge paired ends
* construct sequence table
* Remover quimeras
* rowSums(Tabla de secuencias) >> Remueve muestras con bajo conteo de secuencias
* colSums >> remove samples with low OTU observations 
* assign taxonomy (RDP, Greengenes, Silva)
* add species (if RDP or Silva were used)
* rename columns of taxonomy table (KPCOFGS) #PENDIENTE
* write sequence table and taxonomy table to file
* write unique sequences to file


## Libraries

library(ggplot2)
library(phyloseq); packageVersion("phyloseq")
library(ShortRead)
library(dada2)
library(ape) #library for creating  tree
library(dplyr)


## Import sequences, View sequencing quality profiles

path<-"C:/..." #set path to folder that contains your sequenced samples files
fns <- list.files(path)
fastqs <- fns[grepl(".fastq$", fns)]
fastqs <- sort(fastqs) # Sort ensures forward/reverse reads are in same order
fnFs <- fastqs[grepl("_R1", fastqs)] # Just the forward read files
fnRs <- fastqs[grepl("_R2", fastqs)] # Just the reverse read files

# Get sample names from the first part of the forward read filenames
sample.names <- sapply(strsplit(fnFs, "_"), `[`, 1)

# Fully specify the path for the fnFs and fnRs
fnFs <- paste0(path, fnFs)
fnRs <- paste0(path, fnRs)
plotQualityProfile(fnFs[[1]])
plotQualityProfile(fnFs[[2]])
plotQualityProfile(fnRs[[1]])
plotQualityProfile(fnRs[[2]])


## We can also use fastqc to look at read quality:
cat *R1_001.fastq.gz > forward.fastq.gz
fastqc forward.fastq.gz -o fastq_out/
open /fastq_out/forward_fastqc.html
```



##Based on Sequence quality trim ~ 20 nt from left and anything below Q30 on the right

ptm <- proc.time()
filtFs <- paste0(path, sample.names, "_F_filt.fastq")
filtRs <- paste0(path, sample.names, "_R_filt.fastq")

#trim first 20 nt, filter based on quality, looking for q>30

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, 
                     trimLeft=c(20,20), truncLen=c(290,250), 
                     maxN=0, maxEE=2, truncQ=2, 
                     compress=TRUE, verbose=TRUE) 
head(out)

#keep <- out[,"reads.out"] > 100 # Or other cutoff
#filtFs <- filtFs[keep]
#filtRs <- filtRs[keep]

proc.time() - ptm


##dereplicate

ptm <- proc.time()
derepFs <- derepFastq(filtFs, verbose=TRUE) #dereplicate
derepRs <- derepFastq(filtRs, verbose=TRUE) #dereplicate
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
proc.time() - ptm


##Error rate estimation

ptm <- proc.time()
errF <- learnErrors(derepFs, multithread=TRUE)
errR <- learnErrors(derepRs, multithread=TRUE)
proc.time() - ptm

##Perform joint sample inference and error rate estimation

ptm <- proc.time()
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
proc.time() - ptm

##merge paired ends

mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)


##construct sequence table

seqtab <- makeSequenceTable(mergers)


##remove chimeras

seqtab.nochim <- removeBimeraDenovo(seqtab, verbose=TRUE, multithread = TRUE)


##Track reads through the pipeline

getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
print(track)
#If error in some point, go back to those and roll again



##look at rowSums, see if removing samples with few sequences makes sense (PENDING, to check the order of the samples in the graph.. not making a lot of sense right now: use the table to check final reads per sample)

sample_sum_df<-data.frame(sum=rowSums(seqtab.nochim))
ggplot(data=arrange(sample_sum_df,desc(sum)), aes(x=rownames(sample_sum_df), y=sum))+ggtitle("Sample sequencing depth")+
  geom_bar(stat="identity")+coord_flip()+ylab("Read counts")+xlab("Sample")+ theme_grey(base_size = 18)


##remove sequence variants seen less than a given number of times 

seqtab.nochim = seqtab.nochim[,colSums(seqtab.nochim) > 10]


##write sequence table to file

write.csv2(seqtab.nochim, file = "C:/Users/Rodrigo/Dropbox/00_Estudiantes/LK/SeqComunidadesPaper470/output/seqtab_nochim.csv")


##assign taxonomy (RDP, Silva)

taxa_silva <- assignTaxonomy(seqtab.nochim, "C:/Users/Rodrigo/Dropbox/00_Estudiantes/LK/SeqComunidadesPaper470/DBs/silva_nr_v132_train_set.fa.gz")
taxa_rdp<-assignTaxonomy(seqtab.nochim, "C:/Users/Rodrigo/Dropbox/00_Estudiantes/LK/SeqComunidadesPaper470/DBs/rdp_train_set_16.fa.gz")


##add species level (RDP,Silva)

taxa_silva <- addSpecies(taxa_silva, "C:/Users/Rodrigo/Dropbox/00_Estudiantes/LK/SeqComunidadesPaper470/DBs/silva_species_assignment_v132.fa.gz")
taxa_rdp <- addSpecies(taxa_rdp,"C:/Users/Rodrigo/Dropbox/00_Estudiantes/LK/SeqComunidadesPaper470/DBs/rdp_species_assignment_16.fa.gz")


##Letâ€™s inspect the taxonomic assignments

taxa.print_silva <- taxa_silva # Removing sequence rownames for display only
rownames(taxa.print_silva) <- NULL
head(taxa.print_silva)
taxa.print_rdp <- taxa_rdp # Removing sequence rownames for display only
rownames(taxa.print_rdp) <- NULL
head(taxa.print_rdp)


##write taxonomy assignments to file

write.csv2(taxa_silva, file = "C:/Users/Rodrigo/Dropbox/00_Estudiantes/LK/SeqComunidadesPaper470/output/taxa_silva.csv")
write.csv2(taxa_rdp, file = "C:/Users/Rodrigo/Dropbox/00_Estudiantes/LK/SeqComunidadesPaper470/output/taxa_rdp.csv")


